{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "99d9b702a3fdc1261165d68d8b27b9b4686d1bea"
   },
   "source": [
    "### Relevant imports/variables.\n",
    "These are mostly straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "9f4476aa232321010519c726c0bc57c3597c70b5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "af25616b56a2f6c2f8829b3a2633fb080320b64a"
   },
   "outputs": [],
   "source": [
    "# Some global constants.\n",
    "NUM_PREDICTOR_COLS = 784\n",
    "PREDICTOR_COLS = ['pixel' + str(i) for i in range(NUM_PREDICTOR_COLS)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f88bd988adadc77e96b4719ca2bb2b6254d05d27"
   },
   "source": [
    "### Relevant helper routines\n",
    "These are self explanatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "2e275122c32d97be9fee8a9c6016e434369b5c29"
   },
   "outputs": [],
   "source": [
    "def create_out_of_sample_score(given_pipeline, \n",
    "                               X_train, \n",
    "                               X_test, \n",
    "                               Y_train, \n",
    "                               Y_test):\n",
    "    # Rewrite everything as a pipeline\n",
    "    given_pipeline.fit(X_train, Y_train.values.ravel())\n",
    "    predictions = given_pipeline.predict(X_test)\n",
    "    out_of_sample_score = accuracy_score(predictions, Y_test)\n",
    "    return (out_of_sample_score, predictions)\n",
    "\n",
    "def cross_validate(my_pipeline, X, Y):\n",
    "    cross_val_scores = \\\n",
    "        cross_val_score(my_pipeline, X, Y, scoring='accuracy', cv=5)\n",
    "\n",
    "    return cross_val_scores.mean()\n",
    "\n",
    "def train_test_cross_validate(train_data,\n",
    "                              given_pipeline,\n",
    "                              do_cross_validation=True,\n",
    "                              X_columns=PREDICTOR_COLS, \n",
    "                              Y_columns=['label']):\n",
    "    (X_train, X_test, Y_train, Y_test, X, Y) = \\\n",
    "        get_train_test_data(train_data, X_columns, Y_columns)\n",
    "    out_of_sample_score, predictions_test = \\\n",
    "        create_out_of_sample_score(given_pipeline, X_train, X_test, Y_train, Y_test)\n",
    "\n",
    "    predictions_train = given_pipeline.predict(X_train)\n",
    "    num_correct_predictions_train = int((accuracy_score(predictions_train, Y_train)) * len(Y_train))\n",
    "    num_correct_predictions_train1 = np.sum(predictions_train == Y_train.values.ravel())\n",
    "    print('Training score is {0}'.format((accuracy_score(predictions_train, Y_train)) ))\n",
    "    if do_cross_validation:\n",
    "        cross_validation_score = cross_validate(given_pipeline, X, Y.values.ravel())\n",
    "    else:\n",
    "        cross_validation_score = -1\n",
    "\n",
    "    return (out_of_sample_score, cross_validation_score)\n",
    "\n",
    "def get_train_test_data(train_data,\n",
    "                        X_columns=PREDICTOR_COLS, \n",
    "                        Y_columns=['label']):\n",
    "    # Simple training and testing\n",
    "    X = train_data[X_columns]\n",
    "    Y = train_data[Y_columns]\n",
    " \n",
    "    # Do imputation on relevant columns.\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=0)\n",
    "    return (X_train, X_test, Y_train, Y_test, X, Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "69d5ed4c807ed45fe8687aa68151acfc5b99e6a3"
   },
   "source": [
    "### Reading in data !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "ac442685b751b781ef61afa91a9f126c83c8c817"
   },
   "outputs": [],
   "source": [
    "full_data = pd.read_csv('../input/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ed03b0bf3eae70bb591f215578030b18f31b5d35"
   },
   "source": [
    "### Checking for null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "fda666b14209543d19c136591272e6b29a13f1ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a68c0415c18ec7146eab063a48533266b5ecfe7b"
   },
   "source": [
    "### Split into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "29f1a9e23ddc54f250e45604b4ddafdfaf529064"
   },
   "outputs": [],
   "source": [
    "LEN_TRAIN_SET = int(0.8 * len(full_data))\n",
    "train_data = full_data[0:LEN_TRAIN_SET]\n",
    "validation_data = full_data[LEN_TRAIN_SET:len(full_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "7f60c96701df114d2adcec8c4e3be1ac5058b73e"
   },
   "outputs": [],
   "source": [
    "assert(len(train_data) + len(validation_data) == len(full_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2e6e3defba4bca52fbc49230d55d9b9153a2afd2"
   },
   "source": [
    "### Set up for doing cross validation\n",
    "Later , we try several versions playing with the n_estimators parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c92742dae1e079293aa9bba6e20c3b9ef7a73497"
   },
   "outputs": [],
   "source": [
    "# Commenting out as this takes a long time to complete now. Will revisit later.\n",
    "#(out_of_sample_score, cross_validation_score) = \\\n",
    "#    train_test_cross_validate(full_data,\n",
    "#                              make_pipeline(LogisticRegression()),\n",
    "#                              do_cross_validation=False,\n",
    "#                              X_columns=PREDICTOR_COLS, \n",
    "#                              Y_columns=['label'])\n",
    "    \n",
    "#print(\"Out of sample score is {0}\\nCross val score is {1}\".format(out_of_sample_score, cross_validation_score))\n",
    "#Training score is 0.9443174603174603\n",
    "#Out of sample score is 0.9054285714285715\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "input_pca = PCA()\n",
    "input_pca.fit(train_data[PREDICTOR_COLS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining number of components to use\n",
    "\n",
    "To find out an optimal value, we calculate the amount of variance that is explained by including a specified number of components. For example, if we want to include only 10 components,  we select the top 10 of them by variability and see how much of variance, is explained by all of these together.\n",
    "\n",
    "We plan to plot of the amount of variability explained versus the number of components include and gauge an optimal value from the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a data array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(1,101)\n",
    "Y = np.zeros(100)\n",
    "for i in range(100):\n",
    "    Y[i] = input_pca.explained_variance_ratio_[0:(i+1)].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a185f6390>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1,1,figsize=(16, 9)) \n",
    "ax.set_title('Cum Variability vs Number of PCA components')\n",
    "ax.set_xlabel('Number of PCA components')\n",
    "ax.set_ylabel('Cumulative variability explained')\n",
    "ax.set_yticks(np.arange(0, 0.9, 0.05))\n",
    "ax.set_xticks(np.arange(0, 100, 5))\n",
    "ax.plot(X, Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment\n",
    "\n",
    "Since, we see diminising returns here, we decide to include 50 principal components (as that explains 80% of the variability) and the marginal improvement in variability in addition of an extra components looks very small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation and out of sample testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commenting out as this takes a long time to complete now. Will revisit later.\n",
    "from sklearn.pipeline import Pipeline\n",
    "my_pipeline = Pipeline([('pca', PCA(n_components=50)), ('logistic', LogisticRegression())])\n",
    "(out_of_sample_score, cross_validation_score) = \\\n",
    "    train_test_cross_validate(full_data,\n",
    "                              my_pipeline,\n",
    "                              do_cross_validation=False,\n",
    "                              X_columns=PREDICTOR_COLS, \n",
    "                              Y_columns=['label'])\n",
    "    \n",
    "print(\"Out of sample score is {0}\\nCross val score is {1}\".format(out_of_sample_score, cross_validation_score))\n",
    "#Training score is 0.9443174603174603\n",
    "#Out of sample score is 0.9054285714285715\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "df3f46e1d6a1a86dce687f21dff7d81231c0335a"
   },
   "source": [
    "### Making predictions on  test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "64678f591d152a60bb496d5f1cc9f31637a33e99"
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../input/test.csv')\n",
    "test_predictions = my_pipeline.predict(test_data[PREDICTOR_COLS])\n",
    "test_data['label'] = test_predictions\n",
    "test_data['ImageId'] = test_data.index + 1\n",
    "test_data[['ImageId', 'label']].to_csv('submission_randomforest_sklearn.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
