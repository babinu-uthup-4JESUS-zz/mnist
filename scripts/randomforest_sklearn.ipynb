{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "99d9b702a3fdc1261165d68d8b27b9b4686d1bea"
   },
   "source": [
    "### Relevant imports/variables.\n",
    "These are mostly straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "_uuid": "9f4476aa232321010519c726c0bc57c3597c70b5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "_uuid": "af25616b56a2f6c2f8829b3a2633fb080320b64a"
   },
   "outputs": [],
   "source": [
    "# Some global constants.\n",
    "NUM_PREDICTOR_COLS = 784\n",
    "PREDICTOR_COLS = ['pixel' + str(i) for i in range(NUM_PREDICTOR_COLS)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f88bd988adadc77e96b4719ca2bb2b6254d05d27"
   },
   "source": [
    "### Relevant helper routines\n",
    "These are self explanatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "_uuid": "2e275122c32d97be9fee8a9c6016e434369b5c29"
   },
   "outputs": [],
   "source": [
    "def create_pipeline_and_out_of_sample_score(given_model, \n",
    "                                            X_train, \n",
    "                                            X_test, \n",
    "                                            Y_train, \n",
    "                                            Y_test):\n",
    "    # Rewrite everything as a pipeline\n",
    "    my_pipeline = make_pipeline(given_model)\n",
    "    my_pipeline.fit(X_train, Y_train.values.ravel())\n",
    "    predictions = my_pipeline.predict(X_test)\n",
    "    out_of_sample_score = accuracy_score(predictions, Y_test)\n",
    "    return (my_pipeline, out_of_sample_score, predictions)\n",
    "\n",
    "def cross_validate(my_pipeline, X, Y):\n",
    "    cross_val_scores = \\\n",
    "        cross_val_score(my_pipeline, X, Y, scoring='accuracy', cv=5)\n",
    "\n",
    "    return cross_val_scores.mean()\n",
    "\n",
    "def train_test_cross_validate(train_data,\n",
    "                              given_model,\n",
    "                              do_cross_validation=True,\n",
    "                              X_columns=PREDICTOR_COLS, \n",
    "                              Y_columns=['label']):\n",
    "    (X_train, X_test, Y_train, Y_test, X, Y) = \\\n",
    "        get_train_test_data(train_data, X_columns, Y_columns)\n",
    "    my_pipeline, out_of_sample_score, predictions_test = \\\n",
    "        create_pipeline_and_out_of_sample_score(given_model, X_train, X_test, Y_train, Y_test)\n",
    "\n",
    "    predictions_train = my_pipeline.predict(X_train)\n",
    "    num_correct_predictions_train = int((accuracy_score(predictions_train, Y_train)) * len(Y_train))\n",
    "    num_correct_predictions_train1 = np.sum(predictions_train == Y_train.values.ravel())\n",
    "    print('Training score is {0}'.format((accuracy_score(predictions_train, Y_train)) ))\n",
    "    if do_cross_validation:\n",
    "        cross_validation_score = cross_validate(make_pipeline(given_model), X, Y.values.ravel())\n",
    "    else:\n",
    "        cross_validation_score = -1\n",
    "\n",
    "    return (my_pipeline, out_of_sample_score, cross_validation_score)\n",
    "\n",
    "def get_train_test_data(train_data,\n",
    "                        X_columns=PREDICTOR_COLS, \n",
    "                        Y_columns=['label']):\n",
    "    # Simple training and testing\n",
    "    X = train_data[X_columns]\n",
    "    Y = train_data[Y_columns]\n",
    " \n",
    "    # Do imputation on relevant columns.\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=0)\n",
    "    return (X_train, X_test, Y_train, Y_test, X, Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "69d5ed4c807ed45fe8687aa68151acfc5b99e6a3"
   },
   "source": [
    "### Reading in data !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "_uuid": "ac442685b751b781ef61afa91a9f126c83c8c817"
   },
   "outputs": [],
   "source": [
    "full_data = pd.read_csv('../input/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ed03b0bf3eae70bb591f215578030b18f31b5d35"
   },
   "source": [
    "### Checking for null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "_uuid": "fda666b14209543d19c136591272e6b29a13f1ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a68c0415c18ec7146eab063a48533266b5ecfe7b"
   },
   "source": [
    "### Split into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "_uuid": "29f1a9e23ddc54f250e45604b4ddafdfaf529064"
   },
   "outputs": [],
   "source": [
    "LEN_TRAIN_SET = int(0.8 * len(full_data))\n",
    "train_data = full_data[0:LEN_TRAIN_SET]\n",
    "validation_data = full_data[LEN_TRAIN_SET:len(full_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7f60c96701df114d2adcec8c4e3be1ac5058b73e"
   },
   "outputs": [],
   "source": [
    "assert(len(train_data) + len(validation_data) == len(full_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2e6e3defba4bca52fbc49230d55d9b9153a2afd2"
   },
   "source": [
    "### Set up for doing cross validation\n",
    "Later , we try several versions playing with the n_estimators parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c92742dae1e079293aa9bba6e20c3b9ef7a73497"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is 0.9987936507936508\n"
     ]
    }
   ],
   "source": [
    "NUM_RANDOM_FOREST_ESTIMATORS = 10\n",
    "(my_pipeline, out_of_sample_score, cross_validation_score) = \\\n",
    "    train_test_cross_validate(full_data,\n",
    "                              RandomForestClassifier(random_state=0, n_estimators=NUM_RANDOM_FOREST_ESTIMATORS))\n",
    "    \n",
    "print(\"Out of sample score is {0}\\nCross val score is {1}\".format(out_of_sample_score, cross_validation_score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2b5c03b1d9d37c0fc9f4084e99b5a5c21ddb8a9c"
   },
   "source": [
    "### Train final model on train data and make predictions on validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0d5ef241a2fa2eaa9c168bb8b318c90f84802123"
   },
   "outputs": [],
   "source": [
    "(X_train, X_validation, Y_train, Y_validation, X, Y) = get_train_test_data(full_data)\n",
    "my_model = RandomForestClassifier(random_state=0, n_estimators=NUM_RANDOM_FOREST_ESTIMATORS)\n",
    "\n",
    "# Fit the model\n",
    "my_model.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "# Make and dump predictions to a file.\n",
    "predictions_validation = my_model.predict(X_validation)\n",
    "Y_validation = Y_validation.assign(prediction=predictions_validation)\n",
    "Y_validation['ImageId'] = Y_validation.index\n",
    "Y_validation[['ImageId', 'label', 'prediction']].to_csv('validation_randomforest_sklearn.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "df3f46e1d6a1a86dce687f21dff7d81231c0335a"
   },
   "source": [
    "### Making predictions on  test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on complete dataset\n",
    "(X_train, X_validation, Y_train, Y_validation, X, Y) = get_train_test_data(full_data)\n",
    "my_model = RandomForestClassifier(random_state=0, n_estimators=NUM_RANDOM_FOREST_ESTIMATORS)\n",
    "\n",
    "# Fit the model\n",
    "my_model.fit(X, Y.values.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "64678f591d152a60bb496d5f1cc9f31637a33e99"
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../input/test.csv')\n",
    "test_predictions = my_model.predict(test_data[PREDICTOR_COLS])\n",
    "test_data['label'] = test_predictions\n",
    "test_data['ImageId'] = test_data.index + 1\n",
    "test_data[['ImageId', 'label']].to_csv('submission_randomforest_sklearn.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
